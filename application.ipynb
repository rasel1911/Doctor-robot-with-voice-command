{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898d4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\WALTON\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\WALTON\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\WALTON\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import New_gemini\n",
    "import face_recognition\n",
    "import json\n",
    "# Load the JSON file\n",
    "with open(\"lowercase_diseases_medicines.json\", \"r\") as json_file:\n",
    "    diseases_medicines = json.load(json_file)\n",
    "\n",
    "json_file = open(\"facialemotionmodel.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"facialemotionmodel.h5\")\n",
    "haar_file=cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade=cv2.CascadeClassifier(haar_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for commands...\n",
      "Listening...\n"
     ]
    }
   ],
   "source": [
    "class Assiestant:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.cap=None\n",
    "        self.camera_thread = None\n",
    "        self.camera_thread1 = None\n",
    "        self.camera_thread3 = None\n",
    "        self.Emotion=\"no\" \n",
    "        self.path = \"photos\"\n",
    "        self.mylist = os.listdir(self.path)\n",
    "        self.doc=\"no doctor\"\n",
    "        self.gemin=\"no\"\n",
    "        \n",
    "    def init_camera(self):\n",
    "        self.cap=cv2.VideoCapture(0)\n",
    "        self.camera_thread=threading.Thread(target=self.onlyCam)\n",
    "        self.camera_thread.start()\n",
    "    def enImage(self,Image):\n",
    "        enList=[]\n",
    "        for img in Image:\n",
    "            facLoc=face_recognition.face_locations(img)\n",
    "            enclid = face_recognition.face_encodings(img)[0]\n",
    "            enList.append(enclid)\n",
    "        return enList  \n",
    "    def Name_count(self):\n",
    "        print(\"NAME count\")\n",
    "        self.name = []\n",
    "        self.className = []\n",
    "        for cl in self.mylist:\n",
    "            imlist=cv2.imread(f'{self.path}/{cl}')\n",
    "            #imlist=cv2.cvtColor(imlist, cv2.COLOR_RGB2GRAY)\n",
    "            self.name.append(imlist)\n",
    "            self.className.append(os.path.splitext(cl)[0]) \n",
    "        #print(\"this is\",self.name)\n",
    "        self.enKnown = self.enImage(self.name)\n",
    "        print(self.enKnown)\n",
    "        self.cap =cv2.VideoCapture(0)\n",
    "        self.camera_thread3=threading.Thread(target=self.Face_recog)\n",
    "        self.camera_thread3.start()\n",
    "        #print(self.enKnown)\n",
    "        \n",
    "        \n",
    "    def timeCount(self,name):\n",
    "        with open(\"attandence.csv\",\"r+\") as f: \n",
    "            myDataList = f.readline()\n",
    "            nameList =[]\n",
    "            for line in myDataList:\n",
    "                enty = line.split(\",\")\n",
    "                nameList.append(enty[0])\n",
    "                if name not in nameList:\n",
    "                    now = datetime.now()\n",
    "                    fortime = now.strftime(\"%H:%M:%S\")\n",
    "                    f.writelines(f\"\\n {name},{fortime}\")\n",
    "                    break\n",
    "    def Face_recog(self):\n",
    "        print(\"Start face recognition\")\n",
    "        while True:\n",
    "            t, imgFir= self.cap.read()\n",
    "            imgFlp=cv2.flip(imgFir,1)\n",
    "            img=cv2.cvtColor(imgFlp, cv2.COLOR_RGB2BGR)\n",
    "            imgs=img\n",
    "            faceCurr = face_recognition.face_locations(imgs)\n",
    "            enCurr = face_recognition.face_encodings(imgs,faceCurr)\n",
    "            for i,j in zip(enCurr,faceCurr):\n",
    "                k=np.array(i)\n",
    "                match = face_recognition.compare_faces(self.enKnown,k)\n",
    "                facDis = face_recognition.face_distance(self.enKnown,k)\n",
    "                positionName=np.argmin(facDis)\n",
    "                if match[positionName]:\n",
    "                    nameF=self.className[positionName]\n",
    "                    #print(nameF)\n",
    "                    #print(type(nameF))\n",
    "                    x1,x2,x3,x4=j\n",
    "                    cv2.rectangle(img ,(x4,x1),(x2,x3),(255,0,255),2)\n",
    "                    cv2.putText(img,nameF,(x4+6,x3-6),cv2.FONT_HERSHEY_COMPLEX,1,(0,100,0),1)\n",
    "                    #timeCount(nameF)\n",
    "                    \n",
    "                else:\n",
    "                    x1,x2,x3,x4=j\n",
    "                    #print(x1,x2,x3,x4)\n",
    "                    cv2.rectangle(img ,(x4,x1),(x2,x3),(255,0,255),2)\n",
    "                    cv2.putText(img,\"Unkonwn\",(x4+6,x3-6),cv2.FONT_HERSHEY_COMPLEX,1,(0,128,0),2)\n",
    "            cv2.imshow(\"Output\",img)\n",
    "            if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "                self.release_camera()\n",
    "                break\n",
    "                    \n",
    "                    \n",
    "    def release_camera(self):\n",
    "        if self.cap is not None:\n",
    "            self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            self.cap=None\n",
    "            self.camera_thread.join()\n",
    "            self.camera_thread = None\n",
    "            self.camera_thread1=None\n",
    "            camera_thread3=None\n",
    "            self.Emotion=\"no\"\n",
    "        \n",
    "        \n",
    "    def Gemini(self,com_m):\n",
    "        print(\"run gemini\") \n",
    "        df=New_gemini.Text(com_m)\n",
    "        sentences = df.split('.')[:3]\n",
    "        jk=[]\n",
    "        for i in sentences:\n",
    "            new_str = i.replace('\\n', '')\n",
    "            new_str = i.replace('**', '')\n",
    "            new_str = i.replace('##', '')\n",
    "            new_str = i.replace(':', '')\n",
    "            jk.append(new_str)\n",
    "        li=' '.join(jk)\n",
    "        print(li)\n",
    "        engine.say(li)\n",
    "        # Play the speech\n",
    "        engine.runAndWait()\n",
    "        \n",
    "    def Doctor_voice(self,text_voice):\n",
    "        disease_name = text_voice  # Standardize input\n",
    "        if disease_name in diseases_medicines:\n",
    "            medicines = diseases_medicines[disease_name]\n",
    "            print(f\"Medicines for {disease_name}: {', '.join(medicines)}\")\n",
    "            engine.say(medicines)\n",
    "            # Play the speech\n",
    "            engine.runAndWait()\n",
    "        else:\n",
    "            print(f\"Disease '{disease_name}' not found in the database.\")\n",
    "        \n",
    "    def analyze_command2(self, command):\n",
    "        print(\"analyzed command2 activation:\",command) \n",
    "        if self.doc==\"no doctor\":\n",
    "            if \"on camera\" in command.lower():\n",
    "                if not self.cap or not self.cap.isOpened():\n",
    "                    self.init_camera()\n",
    "            elif \"off camera\" in command.lower():\n",
    "                self.release_camera() \n",
    "            elif \"face\" in command.lower():\n",
    "                self.Name_count()\n",
    "                print(\"face recogbition\")\n",
    "            elif \"emotion\" in command.lower():\n",
    "                self.Emotion=\"yes\"\n",
    "            elif \"no emotion\" in command.lower():\n",
    "                self.Emotion=\"no\"\n",
    "                self.camera_thread1=None\n",
    "                print(\"emotion off\")\n",
    "        elif self.doc==\"doctor\": \n",
    "            text=command.lower()\n",
    "            self.Doctor_voice(text)\n",
    "        elif self.gemin==\"yes\":    \n",
    "            sf=command.lower()\n",
    "            print(\"result: \",sf)\n",
    "            self.Gemini(sf)\n",
    "            self.gemin==\"no\"\n",
    "        else:\n",
    "            print(\"No Command2 mode\")\n",
    "            \n",
    "    def analyze_command(self, command):\n",
    "        if \"on doctor\" in command:\n",
    "            self.doc=\"doctor\"\n",
    "            self.gemin=\"no\"\n",
    "            self.analyze_command2(command)\n",
    "        elif \"off doctor\" in command.lower() or \"of doctor\" in command.lower():\n",
    "            self.doc=\"no doctor\"\n",
    "            self.gemin=\"no\"\n",
    "            self.analyze_command2(command)\n",
    "        elif \"on gemini\" in command.lower(): \n",
    "            self.gemin=\"yes\"\n",
    "            self.doc=\"other\"\n",
    "            print(\"Active Gemini mode\")\n",
    "        else:\n",
    "            print(\"No Command1 mode\")\n",
    "            self.analyze_command2(command)\n",
    "            \n",
    "            \n",
    "            \n",
    "    def camera_open(self):\n",
    "        while self.cap and self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                cv2.imshow(\"Output\",frame)\n",
    "                if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "                    self.release_camera()\n",
    "                    break\n",
    "    \n",
    "    def onlyCam(self):\n",
    "        while self.cap and self.cap.isOpened():\n",
    "            self.ret, self.frame = self.cap.read() \n",
    "            if self.Emotion==\"yes\":\n",
    "                self.camera_thread1=threading.Thread(target=self.camera_feed)\n",
    "                self.camera_thread1.start()\n",
    "                if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "                    self.release_camera()\n",
    "                    break\n",
    "            else:\n",
    "                cv2.imshow(\"Output\",self.frame)\n",
    "                if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "                    self.release_camera()\n",
    "                    break\n",
    "    def camera_feed(self):\n",
    "            labels = {0 : 'angry', 1 : 'disgust', 2 : 'fear', 3 : 'happy', 4 : 'neutral', 5 : 'sad', 6 : 'surprise'}\n",
    "            gray=cv2.cvtColor(self.frame,cv2.COLOR_BGR2GRAY)\n",
    "            faces=face_cascade.detectMultiScale(self.frame,1.3,5)\n",
    "            try: \n",
    "                for (p,q,r,s) in faces:\n",
    "                    image = gray[q:q+s,p:p+r]\n",
    "                    cv2.rectangle(self.frame,(p,q),(p+r,q+s),(255,0,0),2)\n",
    "                    image = cv2.resize(image,(48,48))\n",
    "                    feature = np.array(image)\n",
    "                    img = feature.reshape(1,48,48,1)\n",
    "                    pred = model.predict(img)\n",
    "                    prediction_label = labels[pred.argmax()]\n",
    "                    # print(\"Predicted Output:\", prediction_label)\n",
    "                    # cv2.putText(im,prediction_label)\n",
    "                    cv2.putText(self.frame, '% s' %(prediction_label), (p-10, q-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,2, (0,0,255))\n",
    "                cv2.imshow(\"Output\",self.frame)\n",
    "                cv2.waitKey(1)\n",
    "            except cv2.error:\n",
    "                pass\n",
    "\n",
    "            \n",
    "# Initialize the TTS engine\n",
    "engine = pyttsx3.init()\n",
    "# Text to be converted\n",
    "text =\"Hello, my name is tarbo .i am a doctor robots.\"\n",
    "# Convert text to speech\n",
    "engine.say(text)\n",
    "# Play the speech\n",
    "engine.runAndWait()\n",
    "\n",
    "\n",
    "a=Assiestant()\n",
    "#a.analyze_command(\"on camera\")\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Listening for commands...\")\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "    while True:\n",
    "        print(\"Listening...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source)  # Set timeout to 1 second\n",
    "            command = recognizer.recognize_google(audio)\n",
    "            print(\"Command:\", command)\n",
    "            a.analyze_command(command)\n",
    "        except:\n",
    "            print(\"no command detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3729c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
